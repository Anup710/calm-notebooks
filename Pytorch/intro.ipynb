{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c691dc3a",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Basic operations in tensors, conversion to and from numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21d1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1356257a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether an NVIDIA gpu is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46bfef",
   "metadata": {},
   "source": [
    "A tensor is a multi dimensional array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44b0aac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1 =  tensor([0.5000, 1.7197, 0.0000])\n",
      "e2 =  tensor([[[-9.8885e+32,  1.3775e-42],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# Empty unidimension tensor \n",
    "e1 = torch.empty(3)\n",
    "e2 = torch.empty(2,3,2)\n",
    "\n",
    "print('e1 = ', e1)\n",
    "print('e2 = ', e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717dfdc3",
   "metadata": {},
   "source": [
    "similarly, `torch.rand()`, `torch.randint()` and `torch.zeros()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "287d228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4437, 0.7316],\n",
      "        [0.8719, 0.5862],\n",
      "        [0.5099, 0.9753]]) torch.float32 torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((3,2))\n",
    "print(x, x.dtype, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98792026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1,  1,  0],\n",
      "        [ 3,  0, -2]]) torch.Size([2, 3]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# to create a tensor manually by defining its entries\n",
    "\n",
    "t1 = torch.tensor([[-1,1,0], [3,0,-2]])\n",
    "print(t1, t1.shape, t1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c077e72",
   "metadata": {},
   "source": [
    "if shape/size matches for tensors `t1` and `t2`:\n",
    "\n",
    "- `t1+t2` or `torch.add(t1,t2)` works element-wise. \n",
    "- for inplace addition: `t1.add_(t2)` => modifies t1\n",
    "\n",
    "General rule in pytorch: every function ending in _ performs _inplace_ operation. \n",
    "\n",
    "`torch.sub()`, `torch.mul()`, `torch.div()` perform namesake ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbcde9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  1],\n",
      "        [ 3,  0, -3]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.randint(-1, 3, (2,3))\n",
    "\n",
    "print(t1 + t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff194b1",
   "metadata": {},
   "source": [
    "### Slicing \n",
    "\n",
    "Works exactly like numpy arrays while slicing and picking rows and columns. \n",
    "- `t.item()` can be called on a scalar to get exclusively value stored in the the tensor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f25b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4436, 0.5723, 0.8630],\n",
      "        [0.0426, 0.2397, 0.5697],\n",
      "        [0.2289, 0.5330, 0.5600]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.rand(3,3)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbf62f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4436, 0.0426, 0.2289])\n",
      "torch.Size([3])\n",
      "tensor(0.8630)\n",
      "0.863018274307251\n"
     ]
    }
   ],
   "source": [
    "print(t3[:, 0])\n",
    "print(t3[:, 0].shape)\n",
    "print(t3[0][2])\n",
    "print(t3[0][2].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a0793a",
   "metadata": {},
   "source": [
    "### Reshaping tensors\n",
    "\n",
    "Core: total entries should remain conserved. \n",
    "\n",
    "So, size([3,4]) can be reshaped to size([2,6]) or to size([12])\n",
    "\n",
    "`torch.reshape()` or `torch.view()` methods can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f917ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7127, 0.4149, 0.5111, 0.1839],\n",
      "        [0.5768, 0.1048, 0.7441, 0.1447],\n",
      "        [0.2717, 0.7735, 0.3300, 0.4012]])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.rand(3,4)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64045b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7127, 0.4149, 0.5111, 0.1839, 0.5768, 0.1048],\n",
      "        [0.7441, 0.1447, 0.2717, 0.7735, 0.3300, 0.4012]]) torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "t4_1 = t4.reshape(-1,6) # if all other dimensions are known, plug -1 in the missing one. \n",
    "print(t4_1, t4_1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc81fe1",
   "metadata": {},
   "source": [
    "### Conversion to and from numpy\n",
    "\n",
    "<span style=\"color:#FF0000; font-family: 'Bebas Neue'; font-size: 01em;\">NOTE:</span>\n",
    "While using cpu, a and b in the below examples correspond to the same memory location and hence, modifying one will invariably modify other too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf86213c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_tensor =  tensor([1., 1., 1., 1., 1.]) b_ndarray =  [1. 1. 1. 1. 1.]\n",
      "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "\n",
    "b = a.numpy()\n",
    "\n",
    "print('a_tensor = ', a, 'b_ndarray = ', b)\n",
    "print(type(a), type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f56fdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1) # add 1 to each element of `a`\n",
    "\n",
    "print(b) # b will be modified too, since both variables share pointer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076e1c4",
   "metadata": {},
   "source": [
    "This shared pointer can be avoided if there is a gpu. But you have to move to and from gpu (to cpu) as necessary. A raw form of code is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47d513bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default all tensors are created on the CPU,\n",
    "# but you can also move them to the GPU (only if it's available )\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
    "    # move to CPU again\n",
    "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
    "    # z = z.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
