{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715ec7e4",
   "metadata": {},
   "source": [
    "## Backprop history and importance: \n",
    "\n",
    "It was a common practice as late as 2016 to write your own backward pass instead of the autograd engine we use to call `loss.backward()`, which is why we will spend this lecture trying to get an intuitive sense of backprop by writing own own code to execute it. \n",
    "\n",
    "Essentially we will introduce many __intermediate variables__ to track the flow of gradients a bit like we did in autograd. \n",
    "\n",
    "We will also __revert__ to our simple model of neural network with only a __single hidden layer__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0e7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a46a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "allchars = sorted(set(''.join(words)))\n",
    "\n",
    "stoi = {s:i+1 for i,s in enumerate(allchars) }\n",
    "stoi['.'] = 0\n",
    "\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c70ed5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "words_shuffled = words[:]  # shallow copy -- to preserve across runs\n",
    "random.shuffle(words_shuffled)\n",
    "n1 = int(0.8*len(words_shuffled))\n",
    "n2 = int(0.9*len(words_shuffled))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words_shuffled[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words_shuffled[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words_shuffled[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0854309",
   "metadata": {},
   "source": [
    "Done with boilerplate init code, now to more concrete stuff. \n",
    "\n",
    "Lets define a comparing function to check whether analytically calculated gradients are close to those calculated by pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68dbc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {str(maxdiff):5s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e267a1",
   "metadata": {},
   "source": [
    "Utility of `cmp`: \n",
    "- Line 1: compares all elements of dt and t.grad and compresses it to a single True or False boolean rather than a whole matrix\n",
    "- Line 2: gives come wiggle room during comparison\n",
    "- Line 3: captures the maximum difference bw the two values across the entire gradient matrix\n",
    "- Line 4 is a simple print statement\n",
    "\n",
    "Initializating many of these parameters in non-standard ways because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "implementation of the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fbd49c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5) # kaiming init\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0 # non standard init\n",
    "bnbias = torch.randn((1, n_hidden))*0.1 # non standard init\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19e96ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3016ae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 30]) torch.Size([30, 64]) torch.Size([64])\n",
      "torch.Size([32, 30]) torch.Size([32, 3, 10])\n",
      "torch.Size([27, 10]) torch.Size([32, 3, 10]) torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "print(hprebn.shape, embcat.shape, W1.shape, b1.shape)\n",
    "print(embcat.shape, emb.shape)\n",
    "print(C.shape, emb.shape, Xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c515d3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3569, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3029781e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [8.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1,-1.0], [9,7.0]])\n",
    "t.mean(dim = 1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c85860",
   "metadata": {},
   "source": [
    "All cells above this one are just the basics being carried over. Now lets define: \n",
    "\n",
    "$\\frac{\\partial Loss}{\\partial {logprobs}}$ and start from here as we go back in the chain to compute derivative of loss wrt each intermediate variable. \n",
    "\n",
    "At each step we uncomment each `cmp` call to check the proximity of our analytically calculated grad and pytorch calculated grad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "488514f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27]) torch.Size([32, 1])\n",
      "--------------------\n",
      "torch.Size([32, 27]) torch.Size([32, 64]) torch.Size([64, 27]) torch.Size([27])\n",
      "--------------------\n",
      "torch.Size([32, 64]) torch.Size([32, 64]) torch.Size([1, 64])\n",
      "--------------------\n",
      "torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "# c = a * b \n",
    "# dc/db = a\n",
    "print(counts.shape, counts_sum_inv.shape) # broadcasting is implicit\n",
    "print('--------------------')\n",
    "print(logits.shape, h.shape, W2.shape, b2.shape)\n",
    "print('--------------------')\n",
    "print(hpreact.shape, bnraw.shape, bngain.shape)\n",
    "print('--------------------')\n",
    "print(bndiff2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f423a17f",
   "metadata": {},
   "source": [
    "One tip to deduce formulae of gradients correctly is to check the shape of the original variable; the shape of the grad will also be same, since loss is a scalar. \n",
    "\n",
    "i.e. __if__ shape of logprobs = $(30,40)$ shape of dlogprobs also will be $(30,40)$. \n",
    "\n",
    "<span style=\"color:#FF0000; font-family: 'Bebas Neue'; font-size: 01em;\">Caution:</span><br>\n",
    "1. for `probs = counts_sum_inv * counts`, there are __2 steps__: broadcasting counts_sum_inv and then multiplication, which is why in `dcounts_sum_inv` we sum the gradients along dim 1\n",
    "\n",
    "2. At some places, a `+=` is used to _accumulate_ gradients if a variable is repeated during backpass. \n",
    "\n",
    "3. `A*B` is element-wise multiplication and and `A@B` is matrix multiplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acee655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------GRAD comparison results--------------\n",
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0  \n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0  \n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0  \n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0  \n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0  \n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0  \n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0  \n",
      "logits          | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "h               | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "W2              | exact: False | approximate: True  | maxdiff: 1.30385160446167e-08\n",
      "b2              | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "hpreact         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bngain          | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "bnbias          | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n",
      "bnraw           | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-09\n",
      "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "bnvar           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bndiff2         | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
      "bndiff          | exact: False | approximate: True  | maxdiff: 1.57160684466362e-09\n",
      "bnmeani         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "hprebn          | exact: False | approximate: True  | maxdiff: 1.6007106751203537e-09\n",
      "embcat          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "W1              | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "b1              | exact: False | approximate: True  | maxdiff: 3.259629011154175e-09\n",
      "emb             | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "C               | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: bacmp('logprobs', dlogprobs, logprobs)\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "\n",
    "dprobs = 1/probs * dlogprobs # chain rule\n",
    "\n",
    "dcounts = dprobs * counts_sum_inv # 1st contribution, rest comes from count_sum_inv definition!\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True) # this is tricky -- understand using shape analogy\n",
    "\n",
    "dcounts_sum =   (-1/(counts_sum)**2) * dcounts_sum_inv\n",
    "\n",
    "dcounts2 = torch.ones_like(counts) * dcounts_sum\n",
    "dcounts += dcounts2 \n",
    "\n",
    "dnorm_logits = dcounts * counts #exponential goes unscathed\n",
    "\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True) # similar to dcounts_sum_inv -- broadcasting takes place to beware\n",
    "\n",
    "dh = dlogits @ W2.T  \n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0, keepdims = True) # trick: dim(b2) = [27] => broadcasting happens across rows, so grad sum must be across rows. \n",
    "\n",
    "dhpreact = dh * (1-h**2)\n",
    "\n",
    "dbnbias = dhpreact.sum(0, keepdims=True) # since dim(bnbias) = 1,64 => sum must be along rows (0) while broadcasting -- same as db2\n",
    "dbngain = (dhpreact * bnraw).sum(0, keepdims = True) # from dimensional analysis\n",
    "dbnraw = bngain * dhpreact\n",
    "\n",
    "dbnvar_inv = (dbnraw * bndiff).sum(0, keepdims = True)\n",
    "dbndiff = dbnraw * bnvar_inv # will have to add another components from dbndiff2.grad\n",
    "\n",
    "dbnvar = dbnvar_inv * (-0.5 * ((bnvar + 1e-5)**-1.5)) # simple derivative\n",
    "dbndiff2 = dbnvar * torch.ones_like(bndiff2) * 1/(n-1) # decrypting broadcasting using math\n",
    "\n",
    "dbndiff += 2*bndiff*dbndiff2 # add second component \n",
    "\n",
    "dbnmeani = -1* dbndiff.sum(0, keepdim=True)\n",
    "\n",
    "dhprebn = dbndiff.clone()\n",
    "dhprebn += dbnmeani * 1/n * torch.ones_like(hprebn) # since there were 2 components \n",
    "\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0, keepdim = True)\n",
    "\n",
    "demb = dembcat.view(emb.shape[0], block_size, -1) #since this was just a dim transformation in forward pass too\n",
    "\n",
    "# proceed based on intuition and dimensions of C, emb and Xb\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j]\n",
    "\n",
    "print('---------GRAD comparison results--------------')\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)\n",
    "\n",
    "# backpropagating through exactly all of the variables manually\n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b994669",
   "metadata": {},
   "source": [
    "It does take some effort to trace it all the way back but matching dimensions of variables is really the trick. Understanding broadcasting, accumulation etc operations. \n",
    "\n",
    "### On Bessel's correction \n",
    "\n",
    "In the line: <br>\n",
    "`bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)` <br>\n",
    "whether to use $\\frac{1}{n-1}$ or $\\frac{1}{n}$ is a bit of a confusion in the [original batch norm paper](https://arxiv.org/abs/1502.03167) since they use one during training and other during testing which can, however minutely, give fudged results. Andrej prefers using \n",
    "$\\frac{1}{n-1}$ uniformly. More debate can be found [here](https://math.oxford.emory.edu/site/math117/besselCorrection/)\n",
    "\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "Backprop through cross_entropy but all in one go to complete this challenge look at the mathematical expression of the loss, take the derivative, simplify the expression, and just write it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f05b8db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3568549156188965 diff: 4.76837158203125e-07\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71362777",
   "metadata": {},
   "source": [
    "Similarly, now in computation of `dlogits` we will derive a mathematical relation to prevent calculation of derivatives of `[logprobs, probs, counts, counts_sum, counts_sum_inv, norm_logits, logit_maxes]` to reach upto `dlogits`. \n",
    "\n",
    "__So the goal is:__ `dlogits = f(logits, Yb)` i.e. an attempt to calculate the loss analytically from the logits matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe8675",
   "metadata": {},
   "source": [
    "Andrej's sense of the implementation: \n",
    "\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"images/backprop_logits.jpg\" width = 60%>\n",
    "\n",
    "We are using a simple division rule for calculating the derivatives. \n",
    "\n",
    "This definition of loss for a single examples can be __extended to a batch of examples__ and just has to be divided by 'n' (batch size) since its mean loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd984687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
     ]
    }
   ],
   "source": [
    "dlogits_analytical = F.softmax(logits, 1) # use softmax directly \n",
    "dlogits_analytical[range(n), Yb] -= 1 # pi-1 for indices where i = yb\n",
    "dlogits_analytical /= n\n",
    "\n",
    "cmp('logits', dlogits_analytical, logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c081d2",
   "metadata": {},
   "source": [
    "## Intuition on dlogits\n",
    "\n",
    "Consider the `0th row` following of the following matrices:\n",
    "\n",
    "1. `probs[0]` which is: $\\approx$ `F.softmax(logits, 1)[0]`\n",
    "2. `dlogits[0]*n` which is: the matrix after 2 steps of above cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31ae4d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0660, 0.0886, 0.0187, 0.0501, 0.0194, 0.0883, 0.0275, 0.0347, 0.0175,\n",
       "        0.0304, 0.0367, 0.0320, 0.0354, 0.0270, 0.0348, 0.0141, 0.0096, 0.0202,\n",
       "        0.0176, 0.0553, 0.0535, 0.0215, 0.0228, 0.0671, 0.0635, 0.0261, 0.0215],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47810a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0660,  0.0886,  0.0187,  0.0501,  0.0194,  0.0883,  0.0275,  0.0347,\n",
       "        -0.9825,  0.0304,  0.0367,  0.0320,  0.0354,  0.0270,  0.0348,  0.0141,\n",
       "         0.0096,  0.0202,  0.0176,  0.0553,  0.0535,  0.0215,  0.0228,  0.0671,\n",
       "         0.0635,  0.0261,  0.0215], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0]*n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a16d4",
   "metadata": {},
   "source": [
    "The above 2 are same, except in the place of `Yb[0]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17ae5d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-6.9849e-09, grad_fn=<SumBackward0>) tensor(-0.9825, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(dlogits[0].sum(),              # 0\n",
    "      ( dlogits[0]*n)[Yb[0]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdaff43",
   "metadata": {},
   "source": [
    "What this means is that the gradient sums to zero along each row (for each datapoint). i.e. the gradient at `Yb[i]` tries to 'pull down' the other incorrect gradients by being large negative `-0.9825`, while other grads are small positive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edb47eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ff98aeb980>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e8def",
   "metadata": {},
   "source": [
    "The dark squares with high magnitudes of grad correspond to `Yb[i]`, clearly. \n",
    "\n",
    "## Exercise 3\n",
    "\n",
    "Writing analytical forward and backprop for batch normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ac6f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now: \n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa7497f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec7536",
   "metadata": {},
   "source": [
    "This above step requires lucidity at a crazy level to do analytically. Watch the original explanation from Karpathy [here](https://youtu.be/q8SA3rM6ckI?si=RYYjl8qvM1Z_fT89&t=5830) for best explanation. \n",
    "\n",
    "The derivation is _not trivial_, but still can be worked through with some peace of mind and patience. Maybe some other time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f7dbd",
   "metadata": {},
   "source": [
    "# Piecing it all together:\n",
    "\n",
    "We essentially replace the loss.backward() with different the components for backprop written above and make it into a big coherent code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e93cc136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.8150\n",
      "  10000/ 200000: 2.1582\n",
      "  20000/ 200000: 2.3969\n",
      "  30000/ 200000: 2.4801\n",
      "  40000/ 200000: 2.0356\n",
      "  50000/ 200000: 2.3749\n",
      "  60000/ 200000: 2.3758\n",
      "  70000/ 200000: 2.1325\n",
      "  80000/ 200000: 2.2873\n",
      "  90000/ 200000: 2.1990\n",
      " 100000/ 200000: 2.0091\n",
      " 110000/ 200000: 2.3595\n",
      " 120000/ 200000: 2.0195\n",
      " 130000/ 200000: 2.4874\n",
      " 140000/ 200000: 2.3232\n",
      " 150000/ 200000: 2.2071\n",
      " 160000/ 200000: 1.9344\n",
      " 170000/ 200000: 1.8035\n",
      " 180000/ 200000: 1.8897\n",
      " 190000/ 200000: 1.8330\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#   cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d06bab98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1025378704071045\n",
      "val 2.1408493518829346\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b0e30",
   "metadata": {},
   "source": [
    "This can be reduced to 2.10 on val, but that is about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6ea63d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mriah.\n",
      "myah.\n",
      "see.\n",
      "madhanalorethruthadraege.\n",
      "zered.\n",
      "elin.\n",
      "shi.\n",
      "jenne.\n",
      "elsen.\n",
      "anareelynn.\n",
      "hone.\n",
      "mayshabergihiriel.\n",
      "janie.\n",
      "jennex.\n",
      "terori.\n",
      "brence.\n",
      "ryyshunzels.\n",
      "kayshaston.\n",
      "azhil.\n",
      "samyahsun.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684303ce",
   "metadata": {},
   "source": [
    "__Résumé__: All we did was replace loss.backward() by a custom analytically derived backprop equation. So the output names, are still gibberish looking names. \n",
    "\n",
    "We may have to move to \n",
    "1. more advanced architectures Or\n",
    "2. increase the context length \n",
    "\n",
    "To further improve the model performance, which we will explore in the subsequent lectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e10661",
   "metadata": {},
   "source": [
    "<img title=\"a title\" alt=\"Alt text\" src=\"images/doge_meme.png\" width=40%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
