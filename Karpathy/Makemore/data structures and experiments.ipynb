{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bba63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a12df9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip(a,b,c): [(1, 'apple', 'RCB'), (2, 'ball', 'CSK'), (3, 'cat', 'MI')]\n",
      "('apple', 'RCB')\n",
      "('ball', 'CSK')\n",
      "('cat', 'MI')\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "b = ['apple', 'ball', 'cat', 'dungeon', 'eucalyptus']\n",
    "c = ['RCB', 'CSK', 'MI']\n",
    "\n",
    "# zip object is natively stored as a collection of tuples and\n",
    "# constrained by list with least elements\n",
    "zipped_obj = list(zip(a,b,c))   \n",
    "print(f'Zip(a,b,c): {zipped_obj}')\n",
    "\n",
    "# indexing/slicing is possible\n",
    "for i in zipped_obj:\n",
    "    print(i[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b2df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O l\n",
      "l i\n",
      "i v\n",
      "v i\n",
      "i a\n"
     ]
    }
   ],
   "source": [
    "names = ['Olivia', 'Clementine', 'Claire', 'Martha']\n",
    "\n",
    "for name in names[:1]:\n",
    "    for i,j in zip(name, name[1:]):\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d86e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClaireClementineOliviaMartha\n",
      "Claire; Clementine; Olivia; Martha\n"
     ]
    }
   ],
   "source": [
    "# .join method can be called on any string - which then acts as a connector\n",
    "\n",
    "print(''.join(set(names)))\n",
    "\n",
    "print('; '.join(set(names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc46bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'M', 'O', 'a', 'e', 'h', 'i', 'l', 'm', 'n', 'r', 't', 'v']\n"
     ]
    }
   ],
   "source": [
    "# set: identifies the unique chars in the combined string\n",
    "\n",
    "s1 = set(''.join(set(names)))\n",
    "print(sorted(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7c21e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'M'), (1, 'e'), (2, 'n')]\n",
      "{0: 'M', 1: 'e', 2: 'n', 3: 'l', 4: 'O', 5: 'r', 6: 'C', 7: 'a', 8: 't', 9: 'h', 10: 'm', 11: 'v', 12: 'i'}\n"
     ]
    }
   ],
   "source": [
    "int_to_str = [(i,s) for i,s in enumerate(s1)]\n",
    "print(int_to_str[:3] )# as list\n",
    "\n",
    "# as dict is more useful\n",
    "int_to_str_asdict = {i:s for i,s in enumerate(s1)}\n",
    "print(int_to_str_asdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020dc959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Olivia\n",
      "1 Clementine\n",
      "2 Claire\n",
      "3 Martha\n"
     ]
    }
   ],
   "source": [
    "# enumerate(any_list) create a second iterable along with the entries in any_list itself. \n",
    "for i,j in enumerate(names):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2835816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Severance\n",
      "1 The Boys\n",
      "2 Narcos\n",
      "3 Hangover\n",
      "-----------------\n",
      "0 liminal\n",
      "1 dystopian\n",
      "2 drugs\n",
      "3 nostalgia\n"
     ]
    }
   ],
   "source": [
    "dict = {'Severance':'liminal', 'The Boys': 'dystopian' , 'Narcos':'drugs', 'Hangover':'nostalgia' }\n",
    "\n",
    "# by default iterates over keys \n",
    "for i,j in enumerate(dict):\n",
    "    print(i,j)\n",
    "\n",
    "print('-----------------')\n",
    "\n",
    "# to iterate over values, state explicitly \n",
    "for i,j in enumerate(dict.values()):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e350ef7",
   "metadata": {},
   "source": [
    "## Getting back in shape after a long gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a74f09cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car bus\n",
      "bus train\n"
     ]
    }
   ],
   "source": [
    "l1 = ['car', 'bus', 'train']\n",
    "l2 = ['Mumbai', 'chennai', 'delhi']\n",
    "l3 = [101, -1, 909]\n",
    "\n",
    "for c1,c2 in zip(l1,l1[1:]):\n",
    "    print(c1,c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6988eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c a\n",
      "a r\n"
     ]
    }
   ],
   "source": [
    "for c1,c2 in zip(l1[0],l1[0][1:]):\n",
    "    print(c1,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ea7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jeff', -1), ('William', 4), ('Sam', 5), ('Elon', 7)]\n",
      "[('Elon', 7), ('Sam', 5), ('William', 4), ('Jeff', -1)]\n"
     ]
    }
   ],
   "source": [
    "records = {'Sam':5, 'Elon':7, 'Jeff':-1, 'William':4}\n",
    "\n",
    "print(sorted(records.items(), key = lambda kv: kv[1]))\n",
    "\n",
    "print(sorted(records.items(), key = lambda kv: -kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa36c2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E', 'J', 'S', 'W', 'a', 'e', 'f', 'i', 'l', 'm', 'n', 'o']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list(records.keys())\n",
    "\n",
    "chars = set(''.join(names))\n",
    "chars = sorted(chars)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e60336e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E': 0,\n",
       " 'J': 1,\n",
       " 'S': 2,\n",
       " 'W': 3,\n",
       " 'a': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'i': 7,\n",
       " 'l': 8,\n",
       " 'm': 9,\n",
       " 'n': 10,\n",
       " 'o': 11}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c579364e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 2.0000, 5.0000],\n",
      "        [2.0000, 2.5000, 6.0000]]) tensor([ 8.0000, 10.5000])\n",
      "Post normalization =  tensor([[0.1250, 0.2500, 0.6250],\n",
      "        [0.1905, 0.2381, 0.5714]])\n"
     ]
    }
   ],
   "source": [
    "# normalization along rows\n",
    "\n",
    "import torch \n",
    "\n",
    "N = torch.tensor([[1,2,5], [2,2.5,6]])\n",
    "s = N.sum(dim = 1)\n",
    "print(N,s)\n",
    "\n",
    "for i in range(N.shape[0]):\n",
    "    N[i] = N[i]/s[i]\n",
    "\n",
    "print('Post normalization = ', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f187c4b9",
   "metadata": {},
   "source": [
    "[Check rules of broadcasting](https://docs.pytorch.org/docs/stable/notes/broadcasting.html) and the use of `keepdim` argument in [calculation of row-wise or col-wise sums](https://docs.pytorch.org/docs/stable/generated/torch.sum.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac8e93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "N2 = torch.rand(4,3)\n",
    "sum_with_keepdim = N2.sum(1, keepdim=True)\n",
    "sum_wo_keepdim = N2.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b653c38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1]), torch.Size([4]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_with_keepdim.shape, sum_wo_keepdim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5067f0e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m N2_1 = N2 / sum_with_keepdim\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m N2_2 = \u001b[43mN2\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43msum_wo_keepdim\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "N2_1 = N2 / sum_with_keepdim\n",
    "N2_2 = N2/ sum_wo_keepdim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95b9d2",
   "metadata": {},
   "source": [
    "This error indicates that when `keepdim = False`, the sum tensor is a 1D array and by broadcasting principles apply along the column, _not along row_, as is expected -- which will happen only if `keepdim = True`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bed77f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1252, 0.0233, 0.8515],\n",
       "        [0.4742, 0.0854, 0.4405],\n",
       "        [0.1159, 0.3869, 0.4971],\n",
       "        [0.1630, 0.6686, 0.1684]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N2_1 # normalize along row "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e1dc9",
   "metadata": {},
   "source": [
    "using `torch.nn.functional.one_hot()`: \n",
    "\n",
    "[documentation](https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb8c9e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "torch.arange(0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a878ea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.one_hot(torch.arange(0,6) % 4, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56a13f",
   "metadata": {},
   "source": [
    "another interesting way to generate one hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7806044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 1, 3, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,10,2) % 4 # mod applies for all elements in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54049740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.one_hot(torch.arange(1,10,2) % 4, num_classes=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
