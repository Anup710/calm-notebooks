{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448a026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4917a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6110\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn((1000,50))\n",
    "n_in = X.shape[1]\n",
    "\n",
    "model = nn.Sequential(nn.Linear(n_in, 100, bias = True), nn.Tanh(), nn.Linear(100, 10, bias = True))\n",
    "\n",
    "# calculate total no of params:\n",
    "params = [p for layer in model for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd106279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 10])\n",
      "torch.Size([4, 40, 1])\n",
      "torch.Size([4, 40])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((4,4,10))\n",
    "print(x.shape)\n",
    "\n",
    "y = x.view(4,40,-1)\n",
    "print(y.shape)\n",
    "\n",
    "y = y.squeeze(dim = 2) #squeezing wrong dim keeps y.shape intact\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0edfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = lambda s : len(s)\n",
    "\n",
    "length('Sitaram___/34!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b28382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1107,  2.1620, -0.5630,  0.2965, -1.4963, -0.3796,  0.2467,\n",
       "          -0.5906,  1.5520, -0.8374,  1.4317, -0.4862,  0.2719, -0.8730,\n",
       "           0.5370,  0.7499, -0.0482,  0.0338,  1.4620, -0.1099,  0.9540,\n",
       "           0.2469, -1.3415,  0.0955,  1.9950,  0.6704,  0.8959, -0.3795,\n",
       "          -1.7980,  0.3715,  0.0510,  0.0486,  0.6389, -0.9336,  1.1644,\n",
       "          -1.3099,  0.3662, -0.0218, -0.9578, -0.1643, -0.2078, -0.6938,\n",
       "           0.2492,  0.2351,  0.8860, -0.1524, -1.4133,  0.1853, -0.8533,\n",
       "           0.8834,  0.0347,  0.0535, -0.3400,  0.7325,  0.1745,  0.3168,\n",
       "           0.8193,  0.8609,  1.4911,  1.0582,  0.0394, -0.1799,  0.7785,\n",
       "           1.2308,  1.0810]],\n",
       "\n",
       "        [[ 0.8478,  1.1869,  0.2220, -0.3144,  1.0308,  0.6402, -0.1599,\n",
       "           0.0272,  2.0750,  0.9050, -0.0671, -0.6265, -0.9491,  0.9477,\n",
       "          -0.1043,  1.1445, -0.6795, -0.3166, -0.5478, -1.0564,  0.4550,\n",
       "           1.5283,  0.4419, -1.3361,  0.6346, -0.5142, -0.4427, -1.0389,\n",
       "           0.8008, -0.1240,  1.1453, -2.1173,  3.7248,  1.2365,  2.9068,\n",
       "          -0.1964, -1.9543,  0.3792, -0.6397,  0.4720, -1.8559, -0.3752,\n",
       "          -1.0070, -0.5962,  0.6927,  0.6182, -0.7582,  1.7432,  0.4547,\n",
       "           1.5290, -1.4226, -0.7161, -1.0257, -0.1163,  0.0594, -0.8216,\n",
       "          -0.1557,  0.4815,  0.8220,  0.8046, -0.2242, -1.2501,  0.6717,\n",
       "          -0.2886,  0.2319]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embd = torch.nn.Embedding(65,65)\n",
    "idx = torch.randint(0,65, (2,1))\n",
    "\n",
    "embd(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257feadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8246,  0.6649],\n",
       "         [ 0.6354, -0.7038],\n",
       "         [ 0.1554, -0.1756]],\n",
       "\n",
       "        [[ 0.3554,  0.6081],\n",
       "         [-1.0692, -0.6263],\n",
       "         [-0.4412,  0.3024]],\n",
       "\n",
       "        [[-0.5504, -0.9069],\n",
       "         [-0.8070,  1.1327],\n",
       "         [-0.7694, -1.2626]],\n",
       "\n",
       "        [[ 0.8678,  3.8454],\n",
       "         [ 1.0385, -1.1645],\n",
       "         [ 1.2797,  1.5052]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((4,3,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d012332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8246,  0.6649,  0.6354, -0.7038,  0.1554, -0.1756],\n",
       "        [ 0.3554,  0.6081, -1.0692, -0.6263, -0.4412,  0.3024],\n",
       "        [-0.5504, -0.9069, -0.8070,  1.1327, -0.7694, -1.2626],\n",
       "        [ 0.8678,  3.8454,  1.0385, -1.1645,  1.2797,  1.5052]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(4,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57c1e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1568, -1.8630,  1.2676, -1.0119,  0.4661, -0.0939, -0.0666,  0.7344,\n",
       "         -0.1103, -1.8737, -0.9774,  0.8607,  0.1741,  0.0422, -0.0293, -1.4745,\n",
       "         -0.3180,  1.1389, -0.4212,  1.2010,  1.1812,  0.8048, -0.5440, -1.2262,\n",
       "          0.2798, -0.3235, -0.1248,  0.6768,  0.0531, -1.8871, -0.4745,  0.1631]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 65\n",
    "n_embd = 32\n",
    "block_size = 8\n",
    "\n",
    "position_embedding_table = torch.randn((block_size, n_embd))\n",
    "position_embedding_table[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dc36078",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m span \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print(span)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mposition_embedding_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "span = torch.arange(6)\n",
    "# print(span)\n",
    "\n",
    "position_embedding_table(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5067ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1568, -1.8630,  1.2676, -1.0119,  0.4661, -0.0939, -0.0666,  0.7344,\n",
       "        -0.1103, -1.8737, -0.9774,  0.8607,  0.1741,  0.0422, -0.0293, -1.4745,\n",
       "        -0.3180,  1.1389, -0.4212,  1.2010,  1.1812,  0.8048, -0.5440, -1.2262,\n",
       "         0.2798, -0.3235, -0.1248,  0.6768,  0.0531, -1.8871, -0.4745,  0.1631])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embedding_table[span][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
